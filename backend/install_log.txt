Collecting fastapi==0.115.0 (from -r requirements.txt (line 5))
  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)
Collecting uvicorn==0.32.0 (from uvicorn[standard]==0.32.0->-r requirements.txt (line 6))
  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)
Collecting python-multipart==0.0.12 (from -r requirements.txt (line 7))
  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)
Collecting pydantic==2.9.2 (from -r requirements.txt (line 8))
  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)
Collecting pydantic-settings==2.6.0 (from -r requirements.txt (line 9))
  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)
Collecting sqlalchemy==2.0.36 (from -r requirements.txt (line 12))
  Downloading SQLAlchemy-2.0.36-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)
Collecting asyncpg==0.30.0 (from -r requirements.txt (line 13))
  Downloading asyncpg-0.30.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)
Collecting alembic==1.14.0 (from -r requirements.txt (line 14))
  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)
Collecting redis==5.2.0 (from -r requirements.txt (line 15))
  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)
Collecting sentence-transformers==3.2.1 (from -r requirements.txt (line 18))
  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)
Collecting torch>=2.0.0 (from -r requirements.txt (line 19))
  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl.metadata (26 kB)
Collecting transformers==4.46.3 (from -r requirements.txt (line 20))
  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)
Collecting qdrant-client==1.12.1 (from -r requirements.txt (line 23))
  Downloading qdrant_client-1.12.1-py3-none-any.whl.metadata (10 kB)
Collecting scikit-learn==1.3.2 (from -r requirements.txt (line 26))
  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)
Collecting hdbscan==0.8.40 (from -r requirements.txt (line 27))
  Downloading hdbscan-0.8.40-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)
Collecting umap-learn==0.5.7 (from -r requirements.txt (line 28))
  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)
Collecting spacy==3.5.4 (from -r requirements.txt (line 31))
  Downloading spacy-3.5.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)
Collecting networkx==3.1 (from -r requirements.txt (line 32))
  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)
Collecting python-louvain==0.16 (from -r requirements.txt (line 33))
  Downloading python-louvain-0.16.tar.gz (204 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: httpx==0.28.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (0.28.1)
Collecting beautifulsoup4==4.12.3 (from -r requirements.txt (line 37))
  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)
ERROR: Could not find a version that satisfies the requirement crawl4ai==0.4.247 (from versions: 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.3.6, 0.3.7, 0.3.8, 0.3.71, 0.3.72, 0.3.73, 0.3.74, 0.3.731, 0.3.741, 0.3.742, 0.3.743, 0.3.744, 0.3.745, 0.3.746, 0.4.0, 0.4.1, 0.4.21, 0.4.22, 0.4.23, 0.4.24)
ERROR: No matching distribution found for crawl4ai==0.4.247
