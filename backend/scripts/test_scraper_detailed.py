import asyncio
import sys
import os

# Fix Windows console encoding
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

sys.path.append(os.path.join(os.getcwd(), 'backend'))

from app.services.advanced_scraper import advanced_scraper
from loguru import logger

async def test_detailed():
    url = "https://edition.cnn.com/2025/11/21/americas/faa-warning-venezuela-flights-intl-hnk/index.html"
    print(f"ğŸ§ª Testing scrape on: {url}")
    
    # 1. Check Robots
    domain = advanced_scraper._get_domain(url)
    allowed = advanced_scraper._check_robots_txt(domain, url)
    print(f"ğŸ¤– Robots.txt allowed: {allowed}")
    
    if not allowed:
        print("âŒ Blocked by robots.txt")
        return

    # 2. Extract
    print("ğŸ“¥ Downloading...")
    try:
        article = await asyncio.to_thread(advanced_scraper._extract_with_newspaper, url)
        print(f"ğŸ“„ Title: {article.title}")
        print(f"ğŸ“ Text length: {len(article.text)}")
        
        if len(article.text) < 200:
            print("âš ï¸ Text too short")
            
        # 3. Paywall
        if article.html and advanced_scraper._detect_paywall(article.html, url):
            print("ğŸ’° Paywall detected")
        else:
            print("âœ… No paywall detected")
            
        # 4. Full scrape
        print("\nğŸ”„ Running full scrape_article...")
        result = await advanced_scraper.scrape_article(url)
        if result:
            print("âœ… Scrape SUCCESS!")
            print(result.keys())
        else:
            print("âŒ Scrape FAILED (returned None)")
            
    except Exception as e:
        print(f"âŒ Exception: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_detailed())
