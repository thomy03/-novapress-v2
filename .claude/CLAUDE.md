# NovaPress AI v2 - Documentation Technique
## Bible du Projet - R√©f√©rence Compacte

**Version**: 2.0.0-alpha | **Status**: 100% Complet | **Mise √† jour**: 21 Dec 2025
**Pipeline IA**: 100% OP√âRATIONNELLE + **Advanced RAG** + **TNA** + **Search Enrichment** + **Nexus Causal** + **Persona Rotation** üöÄ
**Synth√®ses**: √âvolutives avec contexte historique, d√©tection de contradictions, timeline narrative, enrichissement web, graphe causal ‚úÖ
**Navigation Dynamique**: 100% TEST√âE - Cat√©gories + EN DIRECT + Breaking Ticker ‚úÖ
**Persona Rotation**: 4 personas + rotation hebdomadaire par cat√©gorie ‚úÖ

---

## üì∞ SOURCES D'ACTUALIT√â (53 news + 5 alternatives)

Le scraper supporte **53 sources de news mondiales** + **5 sources alternatives** dans `backend/app/services/`:

### Sources News (`advanced_scraper.py`)

| Cat√©gorie | Sources | Status |
|-----------|---------|--------|
| **Fran√ßais** | Le Monde, Le Figaro, Lib√©ration, Les Echos, Le Parisien, France Info | Test√© |
| **Anglais US** | CNN, NYT, Washington Post, Reuters, Bloomberg | Test√© |
| **Anglais UK** | The Guardian, BBC News, Financial Times | Test√© |
| **Tech** | TechCrunch, The Verge, Wired, Frandroid | Test√© |
| **Allemand** | Der Spiegel, Bild, Deutsche Welle | Test√© |
| **Espagnol** | El Pa√≠s, El Mundo, Marca, El Universal | Test√© |
| **Italien** | Corriere della Sera, La Repubblica | Test√© |
| **Sport** | L'√âquipe, ESPN, Marca | Test√© |
| **Science** | Science Daily | Test√© |
| **Australie** | Sydney Morning Herald, ABC News Australia | Test√© |
| **Asie** | Times of India, Al Jazeera | Test√© |

### Sources Alternatives (`social_scraper.py`)

| Source | Type | Status |
|--------|------|--------|
| **Reddit** | Discussions (16+ subreddits) | Actif |
| **Hacker News** | Tech news | Actif |
| **ArXiv** | Papers scientifiques | Actif |
| **Wikipedia** | Current events | Actif |
| **Bluesky** | Social d√©centralis√© | Actif |
| ~~YouTube~~ | ~~Vid√©os~~ | D√©sactiv√© (l√©gal) |

### Sources bloqu√©es (robots.txt)
La Tribune, Futura Sciences, Le Soir, SCMP, Japan Times, Korea Herald, RFI, France24, Jeune Afrique, Clar√≠n

---

## ‚ö° QUICK REFERENCE

```powershell
# Frontend
npm run dev                    # http://localhost:3000

# Backend (PowerShell)
cd backend && .\venv\Scripts\Activate.ps1
uvicorn app.main:app --reload --port 5000    # Docs: http://localhost:5000/api/docs

# Pipeline Test
python scripts/run_fast_pipeline.py

# Ports: Frontend:3000 | Backend:5000 | PostgreSQL:5432 | Redis:6380 | Qdrant:6333
```

**DESIGN RULES**: ‚ùå NO gradients | ‚úÖ Newspaper style (NYT, Le Monde) | ‚úÖ Professional only

---

## üìå Stack & Architecture

**Frontend**: Next.js 15.4.6, React 19, TypeScript, Inline Styles
**Backend**: FastAPI 0.115, Python 3.8, PostgreSQL 15, Redis 7, Qdrant 1.12
**IA/ML**: BGE-M3 (1024-dim), HDBSCAN, spaCy fr_core_news_lg, OpenRouter, **Advanced RAG**, **TNA**, **Search Enrichment**

```
Frontend (Next.js) ‚Üí REST/WebSocket ‚Üí Backend (FastAPI)
                                          ‚Üì
Pipeline V6 ULTIMATE:
Scraping ‚Üí Embeddings ‚Üí Dedup ‚Üí Clustering ‚Üí Advanced RAG ‚Üí TNA ‚Üí Search Enrichment ‚Üí LLM ‚Üí Storage
                                               ‚îÇ               ‚îÇ              ‚îÇ
                                               ‚Üì               ‚Üì              ‚Üì
                                    Chunking + Contradictions  Historical   Perplexity + Grok
                                    Fact Density + Entities    Narrative    Web/Social Context
                                          ‚Üì
                    Docker: PostgreSQL:5432 | Redis:6379 | Qdrant:6333
```

---

## üß† Intelligence Avanc√©e (NOUVEAU - 30 Nov 2025)

### Advanced RAG (`backend/app/ml/advanced_rag.py`)

| Feature | Description |
|---------|-------------|
| **Chunking avec Overlap** | D√©coupage intelligent des textes (256 tokens, 50 overlap) |
| **Contradiction Detection** | D√©tecte incoh√©rences entre sources (factual, temporal) |
| **Fact Density Scoring** | Score 0-1 par densit√© factuelle vs opinions |
| **Entity-Centric Index** | Index invers√© entit√©s ‚Üí articles |

### Temporal Narrative Arc (`backend/app/ml/temporal_narrative.py`)

| Feature | Description |
|---------|-------------|
| **Related Syntheses Search** | Recherche s√©mantique des synth√®ses existantes (threshold: 0.75) |
| **Timeline Building** | Chronologie des √©v√©nements d'une histoire |
| **Narrative Arc Detection** | Phase: `emerging` ‚Üí `developing` ‚Üí `peak` ‚Üí `declining` ‚Üí `resolved` |
| **Historical Context** | Enrichissement LLM avec contexte des synth√®ses pr√©c√©dentes |

### Search Enrichment (`backend/app/ml/search_enrichment.py`) - NOUVEAU

| Feature | Description |
|---------|-------------|
| **Perplexity Sonar** | Recherche web temps r√©el + fact-checking (optionnel) |
| **xAI Grok** | Sentiment X/Twitter + breaking news (optionnel) |
| **Combined Enrichment** | Fusion contexte web + social pour synth√®se enrichie |

**Configuration** (`.env`):
```bash
PERPLEXITY_API_KEY=pplx-your-key  # https://docs.perplexity.ai
XAI_API_KEY=xai-your-key          # https://docs.x.ai
```

### Nexus Causal (`backend/app/ml/causal_extraction.py`)

| Feature | Description |
|---------|-------------|
| **Causal Extraction** | Extraction automatique des relations cause-effet |
| **Types de relations** | `causes`, `triggers`, `enables`, `prevents` |
| **Confidence Scoring** | Score 0-1 bas√© sur fact_density + sources |
| **Narrative Flow** | `linear`, `branching`, `circular` |
| **Pre-computed Graph** | 0 appel LLM √† l'affichage (co√ªt = 0) |

### Neural Causal Graph - Frontend (NEW 1 Dec 2025)

| Feature | Description |
|---------|-------------|
| **React Flow** | Graphe interactif avec zoom, pan, minimap |
| **NeuralNode.tsx** | N≈ìuds circulaires avec dendrites dynamiques (3-8) |
| **AnimatedEdge.tsx** | Ar√™tes anim√©es avec cascade de couleurs |
| **Cascade Animation** | Propagation visuelle du n≈ìud source |
| **SynthesisLayout.tsx** | Layout 3 colonnes (280px \| content \| 400px) |

**Composants Frontend** (`app/components/causal/`):
- `NeuralNode.tsx` - N≈ìuds neuraux avec dendrites (plus sources = plus dendrites)
- `AnimatedEdge.tsx` - Ar√™tes avec animation flow + √©paisseur bas√©e sur confidence
- `NeuralCausalGraph.tsx` - Composant principal React Flow
- `NodeDetailPanel.tsx` - Panel d√©tails au clic sur n≈ìud
- `SynthesisLayout.tsx` - Layout 3 colonnes responsive

**Animations CSS** (`globals.css`):
```css
@keyframes neuralPulse { ... }   /* Activation n≈ìud */
@keyframes ripple { ... }         /* Effet ripple */
@keyframes edgeFlow { ... }       /* Animation ar√™te */
@keyframes dendriteExpand { ... } /* Expansion dendrites */
```

### Category Classifier (`backend/app/ml/category_classifier.py`) - NEW 30 Nov 2025

| Feature | Description |
|---------|-------------|
| **Classification NLP** | Keywords matching pour cat√©gorisation automatique |
| **Cat√©gories** | MONDE, TECH, ECONOMIE, POLITIQUE, CULTURE, SPORT, SCIENCES |
| **Confidence Score** | Score 0-1 bas√© sur nombre de keywords match√©s |
| **Int√©gration Pipeline** | Classification automatique apr√®s g√©n√©ration synth√®se |

**Endpoints API**:
- `GET /api/syntheses/breaking` - Synth√®ses pour news ticker
- `GET /api/syntheses/live?hours=24` - Synth√®ses derni√®res X heures
- `GET /api/syntheses/category/{cat}` - Filtrage par cat√©gorie
- `GET /api/trending/categories` - Stats par cat√©gorie avec compteurs
- `GET /api/trending/live-count` - Compteur pour badge EN DIRECT

**Composants Frontend**:
- `NewsTicker.tsx` - Ticker dynamique avec donn√©es API
- `Navigation.tsx` - Cat√©gories avec badges compteurs + EN DIRECT
- `/live/page.tsx` - Page timeline temps r√©el
- `IntelligenceSection.tsx` - Filtrage par cat√©gorie s√©lectionn√©e

### LLM Methods (`backend/app/ml/llm.py`)

```python
# Niveau 1: Standard
synthesize_articles()           # Synth√®se basique

# Niveau 2: Advanced RAG
synthesize_articles_advanced()  # + Chunks factuels + Contradictions

# Niveau 3: RAG + TNA + Search + Causal (ULTIMATE)
synthesize_with_history()       # + Contexte historique + Timeline + Causal chain + Web/Social

# Niveau 4: Persona Rewriting
synthesize_with_persona()       # R√©√©criture avec style/ton d'un persona
```

### Persona Rotation System (`backend/app/ml/persona.py`) - NEW 21 Dec 2025

| Persona ID | Nom | Ton | Style |
|------------|-----|-----|-------|
| `neutral` | NovaPress | Factuel | Journalisme standard |
| `le_cynique` | Edouard Vaillant | Sardonique | Le Canard Encha√Æn√© |
| `l_optimiste` | Claire Horizon | Enthousiaste | Wired/solutions |
| `le_conteur` | Alexandre Duval | Dramatique | Feuilleton narratif |
| `le_satiriste` | Le Bouffon | Absurdiste | Le Gorafi/parodie |

**Rotation Algorithm** (`persona.py`):
```python
# Rotation hebdomadaire par cat√©gorie
offset = ROTATION_ORDER[category]  # POLITIQUE=0, ECONOMIE=1, MONDE=2, etc.
persona_index = (week_number + offset) % len(personas)
```

**Frontend Persona Switcher** (`PersonaSwitcher.tsx`):
- Composant UI pour changer de persona en temps r√©el
- Appel API: `GET /api/syntheses/by-id/{id}/persona/{persona_id}`

**Endpoints Persona**:
- `GET /api/syntheses/personas` - Liste des personas disponibles
- `GET /api/syntheses/rotation-schedule` - Planning rotation actuel
- `GET /api/syntheses/by-id/{id}/persona/{persona_id}` - Synth√®se avec persona

---

## üé® Design System

```typescript
const colors = {
  text: '#000000',           // Titres, contenu
  textSecondary: '#6B7280',  // Metadata
  breaking: '#DC2626',       // BREAKING NEWS
  logoAI: '#2563EB',         // Logo "AI"
  bgMain: '#FFFFFF',
  bgSecondary: '#F9FAFB',
  border: '#E5E5E5',
};
```

---

## üìÅ Structure Principale

```
novapress-v2/
‚îú‚îÄ‚îÄ app/                          # Frontend Next.js
‚îÇ   ‚îú‚îÄ‚îÄ article/[id]/page.tsx     # Page article d√©tail
‚îÇ   ‚îú‚îÄ‚îÄ synthesis/[id]/page.tsx   # Page synth√®se IA (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ components/{layout,articles,auth,ui}/
‚îÇ   ‚îú‚îÄ‚îÄ contexts/{Articles,Auth,Theme}Context.tsx
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                    # useArticles, useDebounce, etc.
‚îÇ   ‚îî‚îÄ‚îÄ lib/api/                  # Client HTTP + services
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/routes/           # articles, search, trending, auth
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/             # pipeline, advanced_scraper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml/                   # embeddings, clustering, llm
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db/                   # qdrant_client, session
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                  # run_fast_pipeline, diagnose
‚îî‚îÄ‚îÄ .claude/CLAUDE.md             # Cette doc
```

---

## üîå API Endpoints

| Endpoint | Status | Description |
|----------|--------|-------------|
| `GET /api/articles` | ‚úÖ | Liste pagin√©e |
| `GET /api/articles/:id` | ‚úÖ | Article unique |
| `GET /api/syntheses` | ‚úÖ | Liste des synth√®ses IA |
| `GET /api/syntheses/:id` | ‚úÖ | Synth√®se unique |
| `GET /api/syntheses/breaking` | ‚úÖ | **NEW** Synth√®ses pour news ticker |
| `GET /api/syntheses/live` | ‚úÖ | **NEW** Synth√®ses derni√®res X heures |
| `GET /api/syntheses/category/{cat}` | ‚úÖ | **NEW** Filtrage par cat√©gorie |
| `GET /api/search?q=` | ‚úÖ | Recherche s√©mantique |
| `GET /api/trending` | ‚úÖ | **NEW** Topics tendances |
| `GET /api/trending/categories` | ‚úÖ | **NEW** Stats par cat√©gorie |
| `GET /api/trending/live-count` | ‚úÖ | **NEW** Compteur EN DIRECT |
| `GET /api/time-traveler/syntheses/:id/timeline` | ‚úÖ | Timeline historique compl√®te |
| `GET /api/time-traveler/syntheses/:id/preview` | ‚úÖ | Preview timeline (sidebar) |
| `GET /api/time-traveler/syntheses/:id/entities` | ‚úÖ | √âvolution des entit√©s |
| `GET /api/causal/syntheses/:id/causal-graph` | ‚úÖ | Graphe causal complet |
| `GET /api/causal/syntheses/:id/causal-preview` | ‚úÖ | Preview causale (sidebar) |
| `GET /api/causal/entities/:name/causal-profile` | ‚úÖ | Profil causal d'une entit√© |
| `GET /api/causal/stats` | ‚úÖ | Statistiques causales |
| `GET /api/admin/status` | ‚úÖ | **NEW** √âtat du pipeline (sans auth) |
| `GET /api/admin/stats` | ‚úÖ | **NEW** Stats admin (avec x-admin-key) |
| `GET /api/admin/sources` | ‚úÖ | **NEW** Sources disponibles |
| `POST /api/admin/pipeline/start` | ‚úÖ | **NEW** Lancer pipeline (avec x-admin-key) |
| `POST /api/admin/pipeline/stop` | ‚úÖ | **NEW** Arr√™ter pipeline (avec x-admin-key) |
| `WS /ws/pipeline` | ‚úÖ | **NEW** WebSocket temps r√©el pipeline |
| `POST /api/auth/login` | ‚è≥ | Authentification |
| `WS /ws/updates` | ‚è≥ | Temps r√©el articles |

---

## ‚öôÔ∏è Configuration (.env)

```bash
DATABASE_URL=postgresql+asyncpg://novapress:password@localhost:5432/novapress_db
REDIS_URL=redis://localhost:6380/0
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=novapress_articles

EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_DEVICE=cpu
OPENROUTER_API_KEY=sk-or-v1-***REDACTED***

CORS_ORIGINS=["http://localhost:3000","http://localhost:3002","http://localhost:3003"]
```

---

## üîß Troubleshooting Rapide

| Erreur | Solution |
|--------|----------|
| Port 3000 in use | `npm run dev -- -p 3002` |
| Redis refused | V√©rifier port 6379, `docker start redis` |
| spaCy model not found | `python -m spacy download fr_core_news_lg` |
| Qdrant collection missing | Cr√©er via script ou API |
| CORS error | Format JSON: `["url1","url2"]` |
| CUDA not available | `.env`: `EMBEDDING_DEVICE=cpu` |
| Port conflict (multiple processes) | Red√©marrer machine, lancer services manuellement |
| Frontend shows demo/mock data | V√©rifier backend actif, red√©marrer frontend |
| 0 clusters generated | V√©rifier `MIN_CLUSTER_SIMILARITY` (0.55 recommand√©) |
| Cluster too large | Sub-clustering automatique ou augmenter `MAX_CLUSTER_SIZE` |
| **Routes API 404 sur Windows** | Cache Python persistant ‚Üí Supprimer `__pycache__`, relancer SANS `--reload` |
| OpenAPI montre anciennes routes | `taskkill /F /IM python.exe` + supprimer tous `__pycache__` + restart |

---

## üìä √âtat du Projet

| Composant | Status | Notes |
|-----------|--------|-------|
| Frontend | 100% ‚úÖ | **Navigation dynamique + News Ticker + Page /live** |
| Backend API | 100% ‚úÖ | Test√©, tous endpoints synth√®ses + trending OK |
| Pipeline IA | 100% ‚úÖ | **53 sources news + 5 alternatives + Classification auto** |
| Scraping Multi-Source | 100% ‚úÖ | **News + Reddit + HN + ArXiv + Wikipedia** |
| Contenu Partiel (Paywall) | 100% ‚úÖ | **Accepte titre + meta_description** |
| Clustering HDBSCAN | 100% ‚úÖ | **Test√© avec 62+ articles** |
| Synth√®se LLM | 100% ‚úÖ | **OpenRouter, articles 400-600 mots** |
| **Pages Synth√®ses** | 100% ‚úÖ | **`/synthesis/[id]` avec contenu complet** |
| **Time-Traveler** | 100% ‚úÖ | **Timeline historique + Entit√©s + Contradictions** |
| **Neural Causal Graph** | 100% ‚úÖ | **React Flow + Layout 3 colonnes + Animations** |
| **Navigation Dynamique** | 100% ‚úÖ | **Cat√©gories + EN DIRECT + Page /live** |
| **Persona Rotation** | 100% ‚úÖ | **4 personas + rotation hebdomadaire + switcher UI** |
| **Connexion FE‚ÜîBE** | 100% ‚úÖ | **Page accueil + Article + Synth√®se OK** |
| **Admin Pipeline UI** | 100% ‚úÖ | **Bouton header + WebSocket + Contr√¥le pipeline** |
| **Pr√©-g√©n√©ration Multi-Personas** | 0% ‚è≥ | G√©n√©ration batch des 5 versions |
| **Agents Relecteurs** | 0% ‚è≥ | Quality assurance personas |
| D√©ploiement | 0% ‚ùå | √Ä planifier |

**Prochaines √©tapes**:
1. ~~Connecter Frontend ‚Üí Backend~~ ‚úÖ FAIT
2. ~~Tester clustering avec >5 articles~~ ‚úÖ FAIT (62 articles, 4 clusters)
3. ~~Valider synth√®se LLM~~ ‚úÖ FAIT (OpenRouter)
4. ~~API Syntheses + Frontend IntelligenceSection~~ ‚úÖ FAIT
5. ~~Activer plus de sources~~ ‚úÖ FAIT (53 news + Reddit/HN/ArXiv/Wikipedia)
6. ~~Support contenu partiel (paywall)~~ ‚úÖ FAIT
7. ~~YouTube~~ ‚ùå D√©sactiv√© (probl√®mes l√©gaux transcripts)
8. ~~Pages synth√®ses d√©di√©es~~ ‚úÖ FAIT (`/synthesis/[id]`)
9. ~~Fix troncature synth√®ses~~ ‚úÖ FAIT (10000 chars)
10. ~~Redesign page accueil~~ ‚úÖ FAIT (Hero + Secondary + Grid layout)
11. ~~Time-Traveler~~ ‚úÖ FAIT (Timeline historique + Entit√©s + Contradictions)
12. ~~Navigation dynamique~~ ‚úÖ FAIT (Cat√©gories + EN DIRECT + /live)
13. ~~Neural Causal Graph~~ ‚úÖ FAIT (React Flow + Layout 3 colonnes + Animations)
14. ~~Persona Rotation~~ ‚úÖ FAIT (4 personas + rotation hebdomadaire)
15. ~~Admin Pipeline UI~~ ‚úÖ FAIT (Bouton header + WebSocket + CORS + API fixes)
16. **Pr√©-g√©n√©ration multi-personas** ‚è≥ √Ä impl√©menter (voir Session 21 Dec)
17. **Agents relecteurs qualit√©** ‚è≥ √Ä impl√©menter (voir Session 21 Dec)
18. **Fix graphes causaux vides** ‚è≥ √Ä impl√©menter (renforcer prompt LLM)
19. D√©ploiement production

---

## ‚ö†Ô∏è R√®gles Critiques

1. **‚ùå JAMAIS** de gradients color√©s
2. **‚úÖ TOUJOURS** style newspaper professionnel
3. **‚úÖ** User-Agent Chrome/121 pour scraping
4. **üîí** NE JAMAIS committer `.env`
5. **‚úÖ** Inline styles pour fiabilit√©

---

## üêõ Fixes Importants (R√©f√©rence)

### Session 21 Dec 2025 - Analyse Architecture Persona + Graphes Causaux

**Objectif**: Analyser les probl√®mes signal√©s et documenter les solutions

#### 1. Perte des sources lors du changement de persona

**Analyse**: Le code dans `syntheses.py:309-316` tente de r√©cup√©rer les articles via `get_articles_by_cluster(cluster_id)`. Cependant, les sources SONT conserv√©es (ligne 335: `persona_synthesis["sourceArticles"] = base_synthesis.get("sourceArticles", [])`).

**Cause probable**: Si `source_articles` n'√©tait pas correctement stock√© lors de la g√©n√©ration initiale, elles seront vides lors de la r√©g√©n√©ration.

**Solution actuelle**: Le code pr√©serve les `sourceArticles` de la synth√®se de base.

**Am√©lioration propos√©e**: Stocker `article_ids` dans la synth√®se et r√©cup√©rer les articles directement par ID plut√¥t que par `cluster_id`.

#### 2. Pr√©-g√©n√©ration multi-personas (√©conomie de co√ªts)

**Probl√®me**: Actuellement, les synth√®ses persona sont g√©n√©r√©es on-demand via l'API, causant des appels LLM √† chaque requ√™te utilisateur.

**Solution propos√©e - Architecture Multi-Persona**:
```python
# Dans pipeline.py:_generate_syntheses()
# Apr√®s g√©n√©ration de la synth√®se de base:

PERSONAS_TO_PREGENERATE = ["le_cynique", "l_optimiste", "le_conteur", "le_satiriste"]

for persona_id in PERSONAS_TO_PREGENERATE:
    persona_synthesis = await self.llm_service.synthesize_with_persona(
        base_synthesis=synthesis,
        articles=articles,
        persona_id=persona_id
    )
    # Stocker avec lien vers synth√®se de base
    persona_synthesis["base_synthesis_id"] = synthesis["id"]
    persona_synthesis["persona_id"] = persona_id
    await self._store_synthesis(persona_synthesis)
```

**Avantages**:
- 0 appel LLM √† la lecture (co√ªt = 0)
- Temps de r√©ponse instantan√©
- Co√ªt batch au moment du pipeline (pr√©visible)

**Stockage Qdrant**:
- Champ `base_synthesis_id` pour lier les versions
- Frontend fetch la version demand√©e directement

#### 3. Agents Relecteurs (Quality Assurance)

**Concept propos√©**: `PersonaQualityReviewer`

```python
class PersonaQualityReviewer:
    """√âvalue la qualit√© d'une synth√®se par rapport au profil persona"""

    def evaluate(self, synthesis: Dict, persona: Persona) -> Dict:
        return {
            "tone_score": self._analyze_tone(synthesis, persona),
            "style_markers": self._count_style_markers(synthesis, persona),
            "signature_present": persona.signature in synthesis.get("signature", ""),
            "vocabulary_alignment": self._check_vocabulary(synthesis, persona),
            "overall_score": 0.0  # Moyenne pond√©r√©e
        }

    def _analyze_tone(self, synthesis, persona) -> float:
        # Analyse sentiment vs ton attendu (cynique, optimiste, etc.)
        pass

    def _count_style_markers(self, synthesis, persona) -> int:
        # Compte les marqueurs stylistiques caract√©ristiques
        pass
```

**Int√©gration pipeline**:
1. Apr√®s g√©n√©ration persona, √©valuer avec le reviewer
2. Si score < threshold (ex: 0.6), r√©g√©n√©rer ou garder version neutre
3. Logger les scores pour monitoring qualit√©

#### 4. Graphes Historiques/Causaux Absents

**Analyse du flux de donn√©es**:
1. `synthesize_with_history()` g√©n√®re `causal_chain` (llm.py:430-443)
2. `qdrant_client.py:446-513` convertit `causal_chain` ‚Üí `causal_graph`
3. API `/api/causal/syntheses/{id}/historical-graph` lit `causal_graph`
4. Frontend `HistoricalCausalGraph.tsx` appelle `causalService.getHistoricalGraph()`

**Causes possibles des graphes vides**:
1. **LLM ne g√©n√®re pas `causal_chain`**: Le prompt demande les relations causales mais le LLM peut ne pas les fournir
2. **Parsing JSON √©choue**: Si le format JSON est incorrect, `causal_chain` est vide
3. **Fallback regex inefficace**: `_extract_causal_fallback()` utilise des patterns qui ne matchent pas le texte

**Solutions propos√©es**:

1. **Renforcer le prompt LLM** (llm.py):
```python
# Ajouter dans synthesize_with_history prompt:
"""
‚ö†Ô∏è CHA√éNE CAUSALE OBLIGATOIRE:
Tu DOIS identifier au minimum 3 relations causales.
Format EXACT requis:
"causal_chain": [
  {"cause": "...", "effect": "...", "type": "causes|triggers|enables", "sources": [...]}
]
Si tu ne trouves pas de relations claires, cr√©e-en bas√©es sur la logique des √©v√©nements.
"""
```

2. **Am√©liorer le fallback regex** (causal_extraction.py):
```python
# Patterns fran√ßais pour extraction causale
CAUSAL_PATTERNS_FR = [
    r"(?P<cause>.+?) a (provoqu√©|caus√©|entra√Æn√©|d√©clench√©) (?P<effect>.+)",
    r"suite √† (?P<cause>.+?), (?P<effect>.+)",
    r"(?P<cause>.+?) a conduit √† (?P<effect>.+)",
    r"en raison de (?P<cause>.+?), (?P<effect>.+)",
]
```

3. **Log de diagnostic** (pipeline.py):
```python
# Apr√®s g√©n√©ration synth√®se
causal_chain = synthesis.get("causal_chain", [])
if not causal_chain:
    logger.warning(f"‚ö†Ô∏è Cluster {cluster['cluster_id']}: No causal_chain generated")
else:
    logger.info(f"‚úÖ Cluster {cluster['cluster_id']}: {len(causal_chain)} causal relations")
```

#### 5. Admin Pipeline - Corrections Interface (21 Dec 2025 soir)

**Objectif**: Rendre la page admin fonctionnelle pour lancer le pipeline manuellement

**Probl√®mes rencontr√©s et solutions**:

1. **Lien Admin manquant dans Header**
   - Ajout√© bouton violet "ADMIN" dans [Header.tsx:93-118](app/components/layout/Header.tsx#L93-L118)
   - Style: fond violet transparent, ic√¥ne ‚öôÔ∏è

2. **CORS bloquant port 3001**
   - Frontend sur port 3001 (3000 occup√©)
   - Fix: Ajout√© `http://localhost:3001` dans:
     - [config.py:68](backend/app/core/config.py#L68)
     - [.env:38](backend/.env#L38)

3. **URL Admin endpoint manquant trailing slash**
   - Avant: `ADMIN: '/api/admin'` ‚Üí URLs `/api/adminstatus`
   - Apr√®s: `ADMIN: '/api/admin/'` ‚Üí URLs `/api/admin/status`
   - Fix: [config.ts:11](app/lib/api/config.ts#L11)

4. **WebSocket URL incorrecte**
   - Erreur: `WebSocket connection to 'ws://localhost:5000/' failed`
   - Cause: `NEXT_PUBLIC_WS_URL=ws://localhost:5000` sans path
   - Fix: Construction URL dynamique dans [page.tsx:46-48](app/admin/pipeline/page.tsx#L46-L48):
   ```typescript
   const wsBaseUrl = process.env.NEXT_PUBLIC_WS_URL || 'ws://localhost:5000';
   const wsUrl = `${wsBaseUrl}/ws/pipeline`;
   ```

5. **apiClient.get() passait headers comme query params**
   - Erreur: `GET /api/admin/stats?headers=%5Bobject+Object%5D`
   - Cause: Signature `get(endpoint, params)` traitait tout comme query string
   - Fix: Nouvelle signature dans [client.ts:122-151](app/lib/api/client.ts#L122-L151):
   ```typescript
   async get<T>(endpoint: string, options?: {
     params?: Record<string, any>;
     headers?: Record<string, string>;
   }): Promise<T>
   ```

6. **NameError: pipeline_state undefined**
   - Erreur backend: `NameError: name 'pipeline_state' is not defined`
   - Cause: Variable utilis√©e sans √™tre d√©finie dans `get_admin_stats()`
   - Fix: [admin.py:136-138](backend/app/api/routes/admin.py#L136-L138):
   ```python
   manager = get_pipeline_manager()
   pipeline_state = manager.get_state()
   ```

7. **Docker auto-restart**
   - Ajout√© `restart: always` √† tous les services dans [docker-compose.yml](backend/docker-compose.yml)

**R√©sultat**: Page admin fonctionnelle avec WebSocket temps r√©el et contr√¥le du pipeline.

---

### Session 1 Dec 2025 (soir) - Neural Causal Graph Interactif ‚úÖ

**Objectif**: Redesign du Nexus Causal en graphe neural interactif

**Nouveaux composants cr√©√©s**:

1. **`NeuralNode.tsx`** - N≈ìuds circulaires avec dendrites
   - Dendrites dynamiques (3-8 selon nombre de sources)
   - Animation pulse √† l'activation
   - Ripple effect au clic
   - Couleur cascade bas√©e sur profondeur

2. **`AnimatedEdge.tsx`** - Ar√™tes anim√©es
   - √âpaisseur bas√©e sur confidence (1-4px)
   - Animation flow continue
   - Glow effect au survol
   - Couleurs par type de relation

3. **`NeuralCausalGraph.tsx`** - Composant React Flow
   - Layout concentrique automatique
   - Minimap + Controls
   - Cascade animation au clic
   - Complexit√© dynamique bas√©e sur donn√©es

4. **`SynthesisLayout.tsx`** - Layout 3 colonnes
   - Gauche: Timeline (280px, sticky)
   - Centre: Contenu synth√®se
   - Droite: Graphe neural (400px, sticky)
   - Responsive: accordions sur mobile

**Package ajout√©**: `reactflow` (13.3.1)

**Bugs TypeScript corrig√©s**:
- `theme.bgMain` ‚Üí `theme.bg` (admin/pipeline, live)
- `flowConfig.bgColor` ‚Üí `${flowConfig.color}15`
- `AnimatedEdgeData` - propri√©t√©s optionnelles
- `apiClient.post` - signature √©tendue pour headers

---

### Session 1 Dec 2025 - Fix Routes API Windows + Navigation Dynamique ‚úÖ

**Probl√®me critique**: Routes `/api/syntheses/breaking`, `/live`, `/category/{cat}` retournaient 404

**Sympt√¥me**:
```json
{"detail":"Synthesis not found"}  // "breaking" captur√© comme synthesis_id
```

**Cause**: FastAPI route ordering + cache Python Windows persistant

**Fixes appliqu√©s**:

1. **Route renomm√©e pour √©viter conflit** (`syntheses.py:186`):
```python
# ‚ùå AVANT - Capturait "breaking", "live" comme ID
@router.get("/{synthesis_id}")

# ‚úÖ APR√àS - Route explicite
@router.get("/by-id/{synthesis_id}")
```

2. **Frontend mis √† jour** (`syntheses.ts:30`, `synthesis/[id]/page.tsx`):
```typescript
// Utiliser le nouveau path
`${API_CONFIG.ENDPOINTS.SYNTHESES}by-id/${id}`
```

3. **Cache Python Windows** (solution):
```powershell
taskkill /F /IM python.exe
Get-ChildItem -Path backend -Recurse -Directory -Filter "__pycache__" | Remove-Item -Recurse -Force
uvicorn app.main:app --host 0.0.0.0 --port 5000  # SANS --reload
```

**R√©sultats test√©s**:
- `/api/syntheses/breaking` ‚Üí 200 OK (72 KB)
- `/api/syntheses/live` ‚Üí 200 OK (417 KB)
- `/api/syntheses/category/TECH` ‚Üí 200 OK (18 KB)

---

### Session 30 Nov 2025 - Fix Clustering + Search Enrichment ‚úÖ

**Probl√®me critique**: 0 clusters valid√©s ‚Üí 0 synth√®ses g√©n√©r√©es

**Diagnostic** (logs pipeline):
```
üìä Initial HDBSCAN: 14 clusters
‚ö†Ô∏è Cluster 0 removed (coherence=0.439 < 0.8)  # TOUS rejet√©s!
‚ö†Ô∏è Cluster 11 too large (52 > 15), marking as noise
‚úÖ Clustering complete: 0 coherent clusters, 179 noise points
```

**Cause**: Seuils de clustering trop stricts (MIN_CLUSTER_SIMILARITY=0.80)

**Fixes appliqu√©s**:

1. **Param√®tres clustering ajust√©s** (`config.py:71-76`):
```python
# ‚ùå AVANT (trop strict)
CLUSTER_SELECTION_EPSILON: float = 0.05
MIN_CLUSTER_SIMILARITY: float = 0.80
MAX_CLUSTER_SIZE: int = 15

# ‚úÖ APR√àS (√©quilibr√©)
CLUSTER_SELECTION_EPSILON: float = 0.08
MIN_CLUSTER_SIMILARITY: float = 0.55
MAX_CLUSTER_SIZE: int = 20
```

2. **Sub-clustering impl√©ment√©** (`clustering.py:52-101`):
```python
def _sub_cluster(self, embeddings, cluster_mask, next_label):
    """Sub-cluster a large cluster into smaller ones."""
    sub_clusterer = HDBSCAN(
        min_cluster_size=max(2, len(cluster_embeddings) // 5),
        cluster_selection_epsilon=0.03,  # Plus strict pour sub-clusters
    )
    # Divise les grands clusters au lieu de les rejeter
```

3. **Search Enrichment int√©gr√©** (`pipeline.py:398-430`):
- Perplexity Sonar: recherche web + fact-checking
- xAI Grok: sentiment X/Twitter + breaking news
- Cl√©s API configur√©es dans `.env` ‚úÖ

**R√©sultat attendu**: Clusters valid√©s + synth√®ses g√©n√©r√©es + enrichissement web/social

---

### Session 29 Nov 2025 (apr√®s-midi) - Sources Cliquables + Anti-Plagiat ‚úÖ

**Probl√®mes identifi√©s**:
1. `num_sources` affichait le nombre d'articles du cluster, pas les sources uniques
2. Les sources n'avaient pas d'URLs (impossible de v√©rifier)
3. Risque de copier-coller dans les synth√®ses LLM

**Fixes appliqu√©s**:

1. **Sources avec URLs** (`pipeline.py:332-351`):
```python
# Extraction des sources uniques avec URLs
source_articles = []
seen_sources = set()
for a in cluster["articles"]:
    source_name = a.get("source_name", "") or a.get("source_domain", "")
    if source_name and source_name not in seen_sources:
        seen_sources.add(source_name)
        source_articles.append({
            "name": source_name,
            "url": a.get("url", ""),
            "title": a.get("raw_title", "")
        })
synthesis["source_articles"] = source_articles
```

2. **Prompt LLM anti-plagiat** (`llm.py:92-99`):
```python
‚ö†Ô∏è R√àGLES DE R√âDACTION OBLIGATOIRES (Copyright/Plagiat):
1. REFORMULE ENTI√àREMENT chaque information avec TES PROPRES MOTS
2. NE COPIE JAMAIS de phrases ou paragraphes des sources
3. Si tu cites, utilise des guillemets ET nomme la source: ¬´...¬ª (selon Le Monde)
4. Synth√©tise et analyse, ne r√©sume pas mot-√†-mot
```

3. **Sources cliquables** (`app/synthesis/[id]/page.tsx`):
- Interface `SourceArticle { name, url, title }`
- Section sources avec liens vers articles originaux
- Affichage: nom source, titre article, lien "Lire l'article original ‚Üí"

**API modifi√©e** (`syntheses.py`):
- Nouveau champ `sourceArticles` dans la r√©ponse
- Fallback vers `sources` (noms seuls) pour r√©trocompatibilit√©

---

### Session 29 Nov 2025 (nuit) - Redesign Page Accueil ‚úÖ

**Objectif**: Moderniser la page d'accueil avec un layout newspaper professionnel
- Mettre en avant l'article avec le meilleur score (Hero)
- Afficher des previews tronqu√©s (click to read more)
- Articles secondaires plus compacts

**Nouveaux composants cr√©√©s**:

1. **`HeroArticle.tsx`** - Article principal full-width (70vh)
   - Image plein √©cran avec gradient overlay
   - Badge "Breaking" et cat√©gorie
   - Titre tronqu√© (120 chars) + r√©sum√© (2 lignes)
   - CTA "Lire l'article"

2. **`SecondaryArticleRow.tsx`** - 2 articles en ligne horizontale
   - Thumbnail 140px + contenu texte
   - Titre sur 2 lignes max + meta donn√©es

3. **`CompactArticleCard.tsx`** - Cartes minimalistes pour la grille
   - Titre uniquement par d√©faut
   - Image appara√Æt au hover avec animation
   - Indicateur ligne au bottom au hover

**Refactoring `ArticleGrid.tsx`**:
```typescript
// Layout 3 sections:
const heroArticle = state.filteredArticles[0];         // Index 0
const secondaryArticles = state.filteredArticles.slice(1, 3);  // Index 1-2
const gridArticles = state.filteredArticles.slice(3);  // Index 3+

// Grid 4 colonnes sur desktop
gridTemplateColumns: 'repeat(4, 1fr)'
```

**Fixes TypeScript**:
```typescript
// CompactArticleCard.tsx:34-46 - ArticleSource est un objet, pas string
const getSourceName = () => {
  if (article.source?.name) return article.source.name;
  if (article.source?.url) {
    const url = new URL(article.source.url);
    return url.hostname.replace('www.', '');
  }
  return 'NovaPress';
};

// client.ts:68-71 - HeadersInit indexing error
const headers: Record<string, string> = { ... };  // Pas HeadersInit

// FeaturedArticle.tsx:196 - Native <img> au lieu de Next.js Image
<img src={article.author.avatar} ... />  // Avec eslint-disable
```

**Fichiers docs exclus du build**: `docs/*.tsx` ‚Üí `docs/*.tsx.example`

---

### Session 29 Nov 2025 (soir) - Pages Synth√®ses + Fix Troncature ‚úÖ

**Bug critique: Synth√®ses tronqu√©es** (`qdrant_client.py:428`):
```python
# ‚ùå AVANT - Articles coup√©s √† ~2000 caract√®res
"summary": str(synthesis.get("summary", ""))[:2000],

# ‚úÖ APR√àS - Articles complets jusqu'√† 10000 caract√®res
"summary": str(synthesis.get("summary", ""))[:10000],
```

**Nouvelle page synth√®se d√©di√©e** (`app/synthesis/[id]/page.tsx`):
- Page compl√®te pour lire les articles de synth√®se IA
- Affiche: titre, metadata, introduction (chapo), body complet, analyse, points cl√©s, sources
- Style newspaper professionnel avec typographie Georgia

**Navigation SynthesisCard** (`app/components/articles/SynthesisCard.tsx`):
- Titre cliquable vers `/synthesis/{id}`
- Lien "Lire l'article complet ‚Üí" ajout√©
- Preview des 2 premiers paragraphes

**R√©sultats test pipeline**: 112 articles d√©couverts depuis 53 sources

---

### Session 28-29 Nov 2025 - Multi-Source Pipeline + Paywall Support ‚úÖ

**Contenu partiel pour articles paywall** (`advanced_scraper.py:841-858`):
```python
# Accepter les articles avec titre + meta_description m√™me si texte < 200 chars
if len(effective_text) < 200:
    has_valid_title = article.title and len(article.title) > 10
    has_meta_desc = article.meta_description and len(article.meta_description) > 30
    if has_valid_title and has_meta_desc:
        effective_text = f"{article.title}. {article.meta_description}"
        is_partial_content = True
```

**YouTube d√©sactiv√©** (`pipeline.py:263-267`):
```python
# YouTube - D√âSACTIV√â
# Raison: Les m√©tadonn√©es (titre/description) sont insuffisantes pour le clustering
# et les transcripts posent des probl√®mes l√©gaux pour usage commercial
# Voir discussion: youtube-transcript-api viole les ToS YouTube
```

**Sources alternatives int√©gr√©es**: Reddit, Hacker News, ArXiv, Wikipedia, Bluesky actifs dans le pipeline.

**R√©sultats test pipeline (29 Nov)**: 53 sources news test√©es, 30+ articles scrap√©s, sources sociales actives.

---

### Session 27 Nov 2025 (soir) - API Syntheses + Frontend ‚úÖ

**Nouveaux composants ajout√©s**:
- `GET /api/syntheses/` - API endpoint pour les synth√®ses IA
- `IntelligenceSection.tsx` - Section frontend affichant les synth√®ses
- `SynthesisCard.tsx` - Carte d'affichage d'une synth√®se

**Dernier test pipeline**: 9 articles scrap√©s, 20 uniques (avec RAG), 0 clusters (articles trop divers)

**Note**: Le clustering HDBSCAN n√©cessite des articles sur des sujets similaires pour cr√©er des clusters. Avec seulement 2 sources et des sujets vari√©s, aucun cluster n'est g√©n√©r√©.

---

### Session 27 Nov 2025 - Pipeline Clustering Test ‚úÖ

**Bug critique d√©duplication**: 59/60 articles marqu√©s comme doublons (98% faux positifs)
```python
# ‚ùå AVANT: backend/app/services/pipeline.py:122
texts = [f"{a.get('title', '')} {a.get('content', '')[:500]}" for a in combined_articles]

# ‚úÖ APR√àS - Utiliser raw_title/raw_text (cl√©s du scraper)
texts = [f"{a.get('raw_title', a.get('title', ''))} {a.get('raw_text', a.get('content', ''))[:500]}" for a in combined_articles]
```

**Erreur m√©moire 128GB**: BGE-M3 avec textes trop longs
```python
# ‚ùå AVANT: backend/app/services/pipeline.py:140
unique_texts = [f"{a.get('raw_title', '')} {a.get('raw_text', '')}" for a in unique_articles]

# ‚úÖ APR√àS - Tronquer √† 500 caract√®res
unique_texts = [f"{a.get('raw_title', '')} {a.get('raw_text', '')[:500]}" for a in unique_articles]
```

**R√©sultats test pipeline**: 62 articles ‚Üí 4 clusters ‚Üí 4 synth√®ses (172.8s)

---

### Session 26 Nov 2025 - Frontend‚ÜîBackend Connection ‚úÖ

**Article page 500 error**: API retourne article directement, pas `{data: article}`
```typescript
// ‚ùå AVANT: app/article/[id]/page.tsx:91
if (data.data) { setArticle(convertApiArticle(data.data)); }

// ‚úÖ APR√àS
if (data && data.id) { setArticle(convertApiArticle(data)); }
```

**next/image hostname error**: Images externes bloqu√©es
```typescript
// next.config.ts - Ajout de unoptimized: true
images: { unoptimized: true, remotePatterns: [...] }
```

**Cache corrompu Next.js**: Erreurs MIME type webpack.js/layout.css
```powershell
# Solution: Nettoyer cache + hard refresh
rm -rf .next && rm -rf node_modules/.cache
# Puis Ctrl+Shift+R dans navigateur
```

---

**Newspaper3k**: Utiliser `Config()` object, pas dict
```python
from newspaper import Config
config = Config()
config.browser_user_agent = 'Mozilla/5.0...'
```

**Qdrant timestamps**: Unix float, pas ISO string
```python
cutoff_time = datetime.now().timestamp()  # PAS .isoformat()
```

**Payload Qdrant**: Fonction `safe_str()` pour None/listes

---

## üìö Liens Utiles

- Next.js: https://nextjs.org/docs
- FastAPI: https://fastapi.tiangolo.com
- BGE-M3: https://huggingface.co/BAAI/bge-m3
- Qdrant: https://qdrant.tech/documentation

---

**Mission**: Transformer le chaos informationnel en intelligence journalistique via l'IA.

**FIN - ~200 lignes au lieu de ~1700**
